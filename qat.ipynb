{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaba99b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline model loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1. Load Fashion MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize and reshape\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_train = np.expand_dims(X_train, -1)  # shape: (60000, 28, 28, 1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "# One-hot encode labels (because pruning loss expects categorical)\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# 2. Load baseline model (make sure it's compiled if needed)\n",
    "baseline_model = load_model('baseline_model1.h5')\n",
    "print(\"✅ Baseline model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLa  (None, 28, 28, 1)         3         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " quant_conv2d (QuantizeWrap  (None, 26, 26, 32)        387       \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_max_pooling2d (Quant  (None, 13, 13, 32)        1         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv2d_1 (QuantizeWr  (None, 11, 11, 64)        18627     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_1 (Qua  (None, 5, 5, 64)          1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten (QuantizeWra  (None, 1600)              1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dropout (QuantizeWra  (None, 1600)              1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 100)               160105    \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWra  (None, 10)                1015      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180141 (703.68 KB)\n",
      "Trainable params: 179926 (702.84 KB)\n",
      "Non-trainable params: 215 (860.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oscarpatrikminj/Documents/IITR/FMNIST/venv/lib/python3.10/site-packages/keras/src/backend.py:5562: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 19s 172ms/step - loss: 0.1707 - accuracy: 0.9357 - val_loss: 0.2109 - val_accuracy: 0.9255\n",
      "Epoch 2/2\n",
      "108/108 [==============================] - 18s 168ms/step - loss: 0.1562 - accuracy: 0.9403 - val_loss: 0.2100 - val_accuracy: 0.9233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1504e53f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Apply Quantization-Aware Training\n",
    "quantized_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantized_model(baseline_model)\n",
    "\n",
    "print(q_aware_model.summary())\n",
    "\n",
    "# Step 5: Compile and train the quantization-aware model\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.fit(X_train, y_train, batch_size=500, epochs=2, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67980b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpa8hi8xrd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpa8hi8xrd/assets\n",
      "/Users/oscarpatrikminj/Documents/IITR/FMNIST/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ QAT TFLite model saved at: /Users/oscarpatrikminj/Documents/IITR/FMNIST/tflite_models/model_qat.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 21:18:42.464203: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-06-05 21:18:42.464218: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-06-05 21:18:42.464434: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpa8hi8xrd\n",
      "2025-06-05 21:18:42.467155: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-06-05 21:18:42.467166: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpa8hi8xrd\n",
      "2025-06-05 21:18:42.476615: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-06-05 21:18:42.562753: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpa8hi8xrd\n",
      "2025-06-05 21:18:42.589156: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 124722 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Convert the QAT model to a quantized TFLite model\n",
    "import pathlib\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_qat = converter.convert()\n",
    "\n",
    "# Step 7: Save the quantized model to your desired directory\n",
    "tflite_models_dir = pathlib.Path('/Users/oscarpatrikminj/Documents/IITR/FMNIST/tflite_models/')\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir / 'model_qat.tflite'\n",
    "tflite_model_file.write_bytes(tflite_model_qat)\n",
    "\n",
    "print(f\"✅ QAT TFLite model saved at: {tflite_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "045e9a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of QAT TFLite model: 0.9202\n",
      " Model size (uncompressed): 183.39 KB\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate the TFLite QAT model on test data\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "pred_list = []\n",
    "for image in X_test:\n",
    "    input_data = np.array(image, dtype=np.float32)\n",
    "    input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n",
    "    interpreter.set_tensor(input_index, input_data)\n",
    "    interpreter.invoke()\n",
    "    prediction = interpreter.get_tensor(output_index)\n",
    "    pred_list.append(np.argmax(prediction))\n",
    "\n",
    "# Step 9: Compute Accuracy\n",
    "accurate_count = sum([1 for i in range(len(pred_list)) if pred_list[i] == np.argmax(y_test[i])])\n",
    "accuracy = accurate_count / len(pred_list)\n",
    "print(f\" Accuracy of QAT TFLite model: {accuracy:.4f}\")\n",
    "\n",
    "# Step 10: Calculate Model Size in KB\n",
    "size_kb = os.path.getsize(tflite_model_file) / 1024\n",
    "print(f\" Model size (uncompressed): {size_kb:.2f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
